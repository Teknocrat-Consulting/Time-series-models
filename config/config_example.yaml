# Storage Forecasting Configuration Example
# Copy this file to config.yaml and adjust settings as needed

# Database Configuration
database:
  enabled: true
  host: localhost
  port: 8086
  username: root
  password: root
  database: telegraf
  measurement: disk
  partition: sda2

# Monitoring Configuration
monitoring:
  enabled: true
  mount_points:
    - /
    - /home
  interval: 60  # seconds
  retention_days: 30

# Forecasting Configuration
forecasting:
  # Model parameters
  model:
    type: arima  # arima, sarima
    auto_fit: true
    max_p: 5
    max_q: 5
    seasonal: false
    seasonal_period: 12
  
  # Forecast settings
  forecast_steps: 30
  confidence_level: 0.95
  
  # Data preprocessing
  preprocessing:
    remove_outliers: true
    outlier_method: iqr  # iqr, zscore
    outlier_threshold: 1.5
    handle_missing: interpolate  # interpolate, forward_fill, mean

# Anomaly Detection
anomaly_detection:
  enabled: true
  method: statistical  # statistical, moving_average
  threshold: 3.0
  window_size: 10

# Alerting Configuration
alerting:
  enabled: true
  thresholds:
    warning: 80  # percentage
    critical: 90  # percentage
  capacity_gb: 1000
  
  # Email settings (optional)
  email:
    enabled: false
    smtp_host: smtp.gmail.com
    smtp_port: 587
    from: alerts@example.com
    to:
      - admin@example.com
    
  # Webhook settings (optional)
  webhook:
    enabled: false
    url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# Visualization Configuration
visualization:
  enabled: true
  save_plots: true
  output_directory: output
  plot_format: png  # png, pdf, svg
  dashboard:
    enabled: true
    refresh_interval: 300  # seconds

# Logging Configuration
logging:
  level: INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: logs/storage_forecast.log
  max_size_mb: 10
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Performance Tuning
performance:
  max_data_points: 10000
  parallel_processing: true
  cache_enabled: true
  cache_ttl: 3600  # seconds

# Schedule Configuration (for automated runs)
schedule:
  enabled: false
  cron: "0 */6 * * *"  # Every 6 hours
  
# Data Sources
data_sources:
  primary: database  # database, csv, api
  csv:
    path: data/disk_usage.csv
    date_column: Date
    value_column: Usage
  api:
    endpoint: http://api.example.com/metrics
    auth_token: YOUR_API_TOKEN